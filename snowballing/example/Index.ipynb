{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Snowballing\n",
    "\n",
    "This is the entry point for the snowballing tools. Before starting, you might want to understand the [project structure](#Structure), [remove the existing files](#Getting-Started) and [configure the database](database/__init__.py).\n",
    "\n",
    "The literature snowballing process is performed by a series of forward and backward snowballing steps. The backward snowballing step follows the references of a paper X, obtaining which papers X cites. The forward snowballing step does the opposite: it follows the citations of a paper X, obatining which papers cite X.\n",
    "\n",
    "For starting the snowballing, it is necessary to have a __start set__. This set can be composed of a single paper or multiple papers. Use the notebook [Insert.ipynb](Insert.ipynb) to insert the start set in the database. This notebook inserts papers in two steps:\n",
    "1. First, it converts references to JSON using a widget. The references can be either in a custom format or in BibTeX\n",
    "2. Then, it loads the json in another widget that produces an insertion code. Note that you must run the insertion code to insert it in the database.\n",
    "\n",
    "After defining the start set, it is possible to perform the __backward snowballing__ step. For the backward snowballing step, it is necessary to extract references from a paper and store them in the database. Unfortunately, we do not have a tool to extract references from pdf files automatically. Thus, the references must be extracted manually. The notebook [Backward.ipynb](Backward.ipynb) assists in the backward snowballing process. Its interface is very similar to the previous Insert.ipynb, with the same two steps. However, it not only inserts the work, but also its citation reference. Note that the first widget in the notebook has a mode (Text) for removing diacritics from text copied from PDF files. This mode can be used to assist copying and pasting references from the PDF. Note also that this notebook assists only with a single work. If you are doing the backward of multiple work, you must repeat the process for each work.\n",
    "\n",
    "The next step is the __forward snowballing__. This project uses google scholar to find the citations of a paper. Thus, it has some limitations: it returns at maximum a 1000 citations, and it has captchas and anti-bot protection which might temporarily block your access if you perform this step too fast. Use the notebook [Forward.ipynb](Forward.ipynb) for this step. Note that this step is easier than the previous one, since google scholar already provides BibTeX for the citations. Hence, it has only the last widget of the previous notebooks, but with an extra pagination step.\n",
    "\n",
    "For __monitoring__ your progress, and checking how many work you have in each category, you can use the notebook [Progress.ipynb](Progress.ipynb). Finally, the notebook [Validate.ipynb](Validate.ipynb) assists in __curating and standardizing__ the database.\n",
    "\n",
    "## Index\n",
    "- [Insert.ipynb](Insert.ipynb)\n",
    "- [Backward.ipynb](Backward.ipynb)\n",
    "- [Forward.ipynb](Forward.ipynb)\n",
    "- [Progress.ipynb](Progress.ipynb)\n",
    "- [Validate.ipynb](Validate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the snowballing data\n",
    "\n",
    "After performing the snowballing, it is possible to analyze it, producing graphs or export work citations to BibTeX. Notebooks for this step of the snowballing are in the [notebooks](notebooks) directory. Here, we list and describe them.\n",
    "\n",
    "\n",
    "### Search Work / BibTeX\n",
    "\n",
    "- Database Work to BibTeX\n",
    "- Notebook: [notebooks/Bibtex.SearchWork.ipynb](notebooks/Bibtex.SearchWork.ipynb)\n",
    "- Extra1: Check if all snowballed approaches appear in the BibTeX\n",
    "- Extra2: Look for unmatched work\n",
    "- Extra3: Recreate BibTeX\n",
    "\n",
    "### Citation graph\n",
    "\n",
    "- Create citation graphs for the work\n",
    "- Notebook: [notebooks/CitationGraph.ipynb](notebooks/CitationGraph.ipynb)\n",
    "\n",
    "### Snowballing provenance\n",
    "\n",
    "- Describe the snowballing process as a prov graph\n",
    "- Requirements: [Graphviz](http://www.graphviz.org/), [ProvToolbox](http://lucmoreau.github.io/ProvToolbox/)\n",
    "- Notebook: [notebooks/SnowballingProvenance.ipynb](notebooks/SnowballingProvenance.ipynb)\n",
    "\n",
    "### Places histogram\n",
    "\n",
    "- Publication place histogram\n",
    "- Notebook: [notebooks/Place.ipynb](notebooks/Place.ipynb)\n",
    "\n",
    "### Approaches page\n",
    "\n",
    "- Create page with all approaches\n",
    "- Notebook: [notebooks/ApproachesHTML.ipynb](notebooks/ApproachesHTML.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "By default, this folder (root) has the following structure\n",
    "- database\n",
    "  - `__init__.py`\n",
    "  - work\n",
    "    - ...\n",
    "    - `y2016.py`\n",
    "    - ...\n",
    "    - `y9999.py`\n",
    "  - citations\n",
    "    - `citation_file.py`\n",
    "    - `other.py`\n",
    "    - ...\n",
    "  - groups\n",
    "    - related\n",
    "      - `__init__.py`\n",
    "      - `approach.py`\n",
    "    - `__init__.py`\n",
    "    - `constants.py`\n",
    "    - `unrelated.py`\n",
    "  - `places.py`\n",
    "- files\n",
    "  - *.pdf\n",
    "- notebooks\n",
    "  - *.ipynb\n",
    "- *.ipynb\n",
    "\n",
    "\n",
    "The `database` directory contains three subdirectoris (work, citation, groups) and two Python file (`__init__.py, places.py`).\n",
    "- `__init__.py` configures the database for your needs.\n",
    "- `places.py` stores all the publication places (conferences, journals, archives, ...).\n",
    "- `work` stores all the discovered work, separated by publication year. If the publication year is not known, please use the `y9999.py` file. \n",
    "- `citations` stores all the citation references of publications. It is recommended to have a distinct citation file for each work you want to do the snowballing. The work has an attribute \"citation_file\" that references in which citation file it is expected to find its citations.\n",
    "- `groups` stores groups of publications as approaches. An approach group may provide extra general information for its publications, and be used in comparisons.\n",
    "\n",
    "The `files` directory might contains pdf files for the published work.\n",
    "\n",
    "The `notebooks` directory contains Jupyter Notebooks for analyzing the snowballing results, producing graphs and generating BibTeX citations.\n",
    "\n",
    "Finally, the root directory contains Jupyter Notebooks for performing the snowballing.\n",
    "\n",
    "\n",
    "If you are going to create a new script/notebook, you need first to import database, then import the snowballing: functions\n",
    "```python\n",
    "import database\n",
    "import snowballing\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "If you download or extracted the `example` from the snowballing project, it comes with some data that is probably not related to your literature snowballing. Thus, it is necessary to remove this data before starting. The data includes `work`, `citations`, `groups`, and `places`, as described in the [project structure section](#Structure).\n",
    "\n",
    "- `work`: for removing all work, delete all files but `y9999.py` in the [database/work directory](database/work).\n",
    "- `citations`: for removing all citations, delete all files in the [database/citations directory](database/citations).\n",
    "- `groups`: for removing all approaches, remove all files but `__init__.py` in the [database/groups/related diretory](database/groups/related), and remove constants from the [database/groups/constants.py](database/groups/constants.py) file.\n",
    "- `places`: for removing all places, you need to open [database/places.py](database/places.py), and remove everything but the imports:\n",
    "```python\n",
    "from snowballing.models import Place, DB\n",
    "from snowballing.common_places import *\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
